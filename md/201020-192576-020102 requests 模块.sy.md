---
show: step
version: 1.0
enable_checker: true
---

# 导入request包

## 新的开始

- 我们安装了nginx服务器
- 使用浏览器访问了服务器上的网页
- 网页有各种状态
	- 200 成功
	- 304 未改变
	- 404 找不到
- 可是这个爬虫怎么搞呢？🤣

### 过程
- 浏览的过程是
	- 浏览器发出请求request
	- 服务器接收请求返回response
	- 浏览器打开response并展示

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630412050376)

- 爬虫其实就是用代码完成这样一个http过程
- 让爬虫发请求
- 让爬虫接收请求

### 请求 requests
- 先从requests开始
- 导入这个包



![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630412431769)

### 查看帮助

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630404683669)

### 照猫画虎
```
import requests
response = requests.get("http://localhost/")
```

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630412591560)

- 好像返回了200的状态码
- 这个r到底是什么呢？

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630412645897)

- 原来是一个response类的对象
- help一下

### Response

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630412922346)

- Response对象包括了一个http 请求的返回结果
- 里面有一些函数和对象

### 只读对象

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630412969842)

- 这些就是可以读出来的

### 再读
- content和text
	- content 是 字节序列
	- text 是 字符串序列

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630413092545)


```
import requests
response = requests.get("http://localhost/")
s_html = response.content
```
## 总结

- 导入了requests模块
- 完成了http get的过程
	- 发出了request
	- 得到了response
	- 状态码200
- 但是读到的内容是
	- 字节序列
	- 字符串序列
- 如何解析html语言呢？🤔
- 下次再说
